{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a90d715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "True\n",
      "True\n",
      "使用训练设备: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 首先确认您的 PyTorch 版本是否支持 Metal 后端（Apple GPU 加速）\n",
    "print(torch.version.__version__)  # 应显示2.0.0或更高\n",
    "print(torch.backends.mps.is_available())  # 应显示True\n",
    "print(torch.backends.mps.is_built())     # 应显示True\n",
    "\n",
    "# 设备配置 - 启用AMD Radeon GPU加速\n",
    "# 设置设备，优先使用GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"使用训练设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50bb78d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵尺寸        设备      数据类型    平均时间(s)         \n",
      "--------------------------------------------------\n",
      "100x100     CPU     FP32    0.000021\n",
      "1000x1000    CPU     FP32    0.006491\n",
      "5000x5000    CPU     FP32    0.719043\n",
      "10000x10000   CPU     FP32    9.737196\n",
      "100x100     MPS     FP16    0.001767\n",
      "1000x1000    MPS     FP16    0.007567\n",
      "5000x5000    MPS     FP16    0.997615\n",
      "10000x10000   MPS     FP16    7.624653\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def test_performance(shape, device, use_fp16=True):\n",
    "    \"\"\"测试矩阵乘法性能（不使用Dynamo）\"\"\"\n",
    "    device = torch.device(device)\n",
    "    dtype = torch.float16 if use_fp16 else torch.float32\n",
    "    \n",
    "    # 创建并重用张量（减少内存分配）\n",
    "    a = torch.randn(shape, device=device, dtype=dtype)\n",
    "    b = torch.randn(shape, device=device, dtype=dtype)\n",
    "    test_epoch = 3 # 测试周期数\n",
    "    epoch = 5  #周期 \n",
    "    \n",
    "    # 预热\n",
    "    for _ in range(test_epoch):\n",
    "        c = a @ b\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    # 计时\n",
    "    start = time.time()\n",
    "    for _ in range(epoch):\n",
    "        c = a @ b\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    end = time.time()\n",
    "    \n",
    "    return (end - start) / epoch\n",
    "\n",
    "# 测试不同尺寸\n",
    "matrix_sizes = [100, 1000, 5000, 10000]\n",
    "print(f\"{'矩阵尺寸':<12}{'设备':<8}{'数据类型':<8}{'平均时间(s)':<16}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 测试CPU\n",
    "for n in matrix_sizes:\n",
    "    shape = (n, n)\n",
    "    cpu_time = test_performance(shape, \"cpu\", use_fp16=False)\n",
    "    print(f\"{n}x{n:<8}{'CPU':<8}{'FP32':<8}{cpu_time:.6f}\")\n",
    "\n",
    "# 测试MPS\n",
    "if torch.backends.mps.is_available():\n",
    "    for n in matrix_sizes:\n",
    "        shape = (n, n)\n",
    "        mps_time = test_performance(shape, \"mps\", use_fp16=True)\n",
    "        print(f\"{n}x{n:<8}{'MPS':<8}{'FP16':<8}{mps_time:.6f}\")\n",
    "else:\n",
    "    print(\"MPS不可用\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba13474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵尺寸        设备      数据类型    是否编译    平均时间(s)         \n",
      "------------------------------------------------------------\n",
      "5000x5000    MPS     FP16    否       0.971096\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dynamo is not supported on Python 3.12+",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mMPS\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mFP16\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m否\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtime_base\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# 编译\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m time_compiled = test_compiled_performance(shape, \u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m, use_fp16=\u001b[38;5;28;01mTrue\u001b[39;00m, use_compile=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mMPS\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mFP16\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m是\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<8\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtime_compiled\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m加速比: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_base/time_compiled\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtest_compiled_performance\u001b[39m\u001b[34m(shape, device, use_fp16, use_compile)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# 编译函数\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_compile:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     matmul = torch.compile(matmul, backend=\u001b[33m\"\u001b[39m\u001b[33minductor\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 预热\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/torch/__init__.py:1801\u001b[39m, in \u001b[36mcompile\u001b[39m\u001b[34m(model, fullgraph, dynamic, backend, mode, options, disable)\u001b[39m\n\u001b[32m   1799\u001b[39m \u001b[38;5;66;03m# Temporary until we get proper support for python 3.12\u001b[39;00m\n\u001b[32m   1800\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.version_info >= (\u001b[32m3\u001b[39m, \u001b[32m12\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1801\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDynamo is not supported on Python 3.12+\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1803\u001b[39m \u001b[38;5;66;03m# Decorator mode\u001b[39;00m\n\u001b[32m   1804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: Dynamo is not supported on Python 3.12+"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def test_compiled_performance(shape, device, use_fp16=True, use_compile=True):\n",
    "    \"\"\"测试编译后的矩阵乘法性能\"\"\"\n",
    "    device = torch.device(device)\n",
    "    dtype = torch.float16 if use_fp16 else torch.float32\n",
    "    \n",
    "    # 创建张量\n",
    "    a = torch.randn(shape, device=device, dtype=dtype)\n",
    "    b = torch.randn(shape, device=device, dtype=dtype)\n",
    "    \n",
    "    # 定义计算函数\n",
    "    def matmul(a, b):\n",
    "        return a @ b\n",
    "    \n",
    "    # 编译函数\n",
    "    if use_compile:\n",
    "        matmul = torch.compile(matmul, backend=\"inductor\")\n",
    "    \n",
    "    # 预热\n",
    "    for _ in range(2):\n",
    "        c = matmul(a, b)\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    # 计时\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(5):\n",
    "        c = matmul(a, b)\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    end = time.perf_counter()\n",
    "    \n",
    "    return (end - start) / 5\n",
    "\n",
    "# 测试不同尺寸\n",
    "matrix_sizes = [5000, 10000]\n",
    "print(f\"{'矩阵尺寸':<12}{'设备':<8}{'数据类型':<8}{'是否编译':<8}{'平均时间(s)':<16}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# 测试MPS性能（编译与未编译对比）\n",
    "if torch.backends.mps.is_available():\n",
    "    for n in matrix_sizes:\n",
    "        shape = (n, n)\n",
    "        \n",
    "        # 未编译\n",
    "        time_base = test_compiled_performance(shape, \"mps\", use_fp16=True, use_compile=False)\n",
    "        print(f\"{n}x{n:<8}{'MPS':<8}{'FP16':<8}{'否':<8}{time_base:.6f}\")\n",
    "        \n",
    "        # 编译\n",
    "        time_compiled = test_compiled_performance(shape, \"mps\", use_fp16=True, use_compile=True)\n",
    "        print(f\"{n}x{n:<8}{'MPS':<8}{'FP16':<8}{'是':<8}{time_compiled:.6f}\")\n",
    "        print(f\"加速比: {time_base/time_compiled:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
