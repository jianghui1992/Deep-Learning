{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72b1d2b",
   "metadata": {},
   "source": [
    "### 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481aab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS可用: True\n",
      "矩阵尺寸        设备      平均时间(s)         \n",
      "----------------------------------------\n",
      "100x100     CPU     0.000001\n",
      "1000x1000    CPU     0.000635\n",
      "5000x5000    CPU     0.058500\n",
      "100x100     MPS     0.000036\n",
      "1000x1000    MPS     0.000947\n",
      "5000x5000    MPS     0.099857\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dcb85c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: torchinfo in /usr/local/anaconda3/envs/DL/lib/python3.12/site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库，torchinfo用于查看模型结构\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bddce",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87c584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LeNet-5模型（适配32×32输入）\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # 卷积层1：输入1个通道，输出6个通道，卷积核大小为5x5\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        # 卷积层2：输入6个通道，输出16个通道，卷积核大小为5x5\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        # 全连接层1：输入16x5x5个节点，输出120个节点\n",
    "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
    "        # 全连接层2：输入120个节点，输出84个节点\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        # 输出层：输入84个节点，输出10个节点\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))                   # 卷积+Relu激活\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=2)  # 最大池化\n",
    "        x = torch.relu(self.conv2(x))                   # 卷积+Relu激活\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=2)  # 最大池化\n",
    "        x = x.view(-1, 16 * 5 * 5)                      # 将多维张量展平为一维张量\n",
    "        x = torch.relu(self.fc1(x))                     # 全连接+Relu激活\n",
    "        x = torch.relu(self.fc2(x))                     # 全连接+Relu激活\n",
    "        x = self.fc3(x)                                 # 输出层\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6dbeb",
   "metadata": {},
   "source": [
    "### 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42692239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LeNet5                                   [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 6, 28, 28]            156\n",
       "├─Conv2d: 1-2                            [1, 16, 10, 10]           2,416\n",
       "├─Linear: 1-3                            [1, 120]                  48,120\n",
       "├─Linear: 1-4                            [1, 84]                   10,164\n",
       "├─Linear: 1-5                            [1, 10]                   850\n",
       "==========================================================================================\n",
       "Total params: 61,706\n",
       "Trainable params: 61,706\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.25\n",
       "Estimated Total Size (MB): 0.30\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看模型结构及参数量，input_size表示示例输入数据的维度信息\n",
    "# input_size参数是一个元组，包含4个值，分别表示(批量大小, 通道数, 高, 宽)\n",
    "# 这里LeNet用于处理32x32的单通道灰度图像，batch_size可以任意指定（如1），所以input_size=(1, 1, 32, 32)\n",
    "# batch_size是影响输出形状(output shape),不影响模型参数量(param)\n",
    "summary(LeNet5(), input_size=(1, 1, 32, 32))\n",
    "# 输出结构\n",
    "# Layer: 层级定义\n",
    "# Output Shape : 输出的数据结构\n",
    "# Param : 当前层的参数\n",
    "# 输出的7个值含义如下：\n",
    "# 1. Total params: 模型中所有参数的总数（可训练+不可训练），这里是61706\n",
    "# 2. Trainable params: 可训练参数的数量（会被优化器更新），这里是61706\n",
    "# 3. Non-trainable params: 不可训练参数数量（不会被优化器更新），这里是0\n",
    "# 4. Total mult-adds: 前向传播时的乘加运算总量，衡量计算量，单位是百万次（MB=百万次，不是兆字节）\n",
    "# 5. Input size (MB): 输入张量占用的内存大小（以MB为单位）\n",
    "# 6. Forward/backward pass size (MB): 前向和反向传播过程中所有中间激活值占用的内存总量\n",
    "# 7. Params size (MB): 所有参数占用的内存大小\n",
    "# 8. Estimated Total Size (MB): 估算的总内存占用（输入+激活+参数）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbfb1c",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04cbc625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use device is mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aace8e31f6e48a99702d5d466246575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0   Loss: 34.3998  Accuracy: 0.1135  \n",
      "Epoch: 1   Loss: 3.3342   Accuracy: 0.1135  \n",
      "Epoch: 2   Loss: 3.3342   Accuracy: 0.1135  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/cd/6gw212g16h3dr3bbgjtd725r0000gn/T/ipykernel_76458/2185546422.py\", line 109, in <module>\n",
      "    train(model,device, train_loader, optimizer, scheduler, loss_history)\n",
      "  File \"/var/folders/cd/6gw212g16h3dr3bbgjtd725r0000gn/T/ipykernel_76458/2185546422.py\", line 80, in train\n",
      "    total_loss += loss.item()           # 记录训练集loss\n",
      "                  ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/executing/executing.py\", line 317, in executing\n",
      "    args = executing_cache[key]\n",
      "           ~~~~~~~~~~~~~~~^^^^^\n",
      "KeyError: (<code object run_code at 0x7fa9761718a0, file \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3631>, 140365807425696, 252)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 2176, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1182, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1053, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 861, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 746, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, context, tb_offset) if etb else []\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 848, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/stack_data/core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/stack_data/utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/stack_data/core.py\", line 555, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/stack_data/core.py\", line 520, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/executing/executing.py\", line 369, in executing\n",
      "    args = find(source=cls.for_frame(frame), retry_cache=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/executing/executing.py\", line 252, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/executing/executing.py\", line 270, in for_filename\n",
      "    result = source_cache[filename] = cls._for_filename_and_lines(filename, lines)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/executing/executing.py\", line 281, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/stack_data/core.py\", line 81, in __init__\n",
      "    self.asttokens()\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/executing/executing.py\", line 413, in asttokens\n",
      "    return ASTTokens(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/asttokens/asttokens.py\", line 114, in __init__\n",
      "    self._tokens = list(self._translate_tokens(tokens))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/asttokens/asttokens.py\", line 143, in _translate_tokens\n",
      "    self._line_numbers.line_to_offset(end[0], end[1]))\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/asttokens/line_numbers.py\", line 64, in line_to_offset\n",
      "    return min(self._line_offsets[line] + max(0, column), self._text_len)\n",
      "                                          ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/envs/DL/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 76586) is killed by signal: Abort trap: 6. \n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm  # tqdm用于显示进度条并评估任务时间开销\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 定义模型、优化器、损失函数\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"use device is\",device)\n",
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device) \n",
    "# Adam结果(精确度等)会更稳定一些,但是训练速度会比较慢\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# 使用SGD+scheduler训练速度会最快\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "# 定义余弦学习率调度器，T_max=5 表示每 5 个 epoch 完成一个周期(从最大值到最小值就是一个周期,从最小值到最大值也算一个周期)\n",
    "# 周期特性：若训练周期超过 T_max，学习率会重新上升并循环变化（需结合 T_max 和总训练周期数设置）\n",
    "# 默认行为：若训练总周期数 ≤ T_max，学习率将单调递减至 eta_min\n",
    "# 优势：\n",
    "#   避免局部最优：学习率的周期性变化有助于模型跳出局部最小值，探索更广阔的参数空间。\n",
    "#   精细收敛：训练后期学习率降低，使模型能够更精确地收敛到全局最优解附近(所以最好多几个周期,这里时间因素,只训练2个周期)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=5, eta_min=0.0001)\n",
    "\n",
    "\n",
    "# 设置数据变换\n",
    "# transforms.Compose用于将多个变换操作串联起来\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Pad(2),  # 每个图像边缘padding 2像素，使图像从28×28变为32×32\n",
    "        transforms.ToTensor(),  # 把图片或转换为PyTorch的FloatTensor，并且归一化到[0,1]区间\n",
    "        # 此时模型输入分布在[0.0,1.0] 使用 Normalize：模型输入分布被调整为均值≈0，标准差≈1，更符合模型期望的输入分布\n",
    "        # 深度学习模型通常在标准化数据（均值≈0，标准差≈1）上表现更好，主要原因是：\n",
    "        #   数值稳定性：避免因输入值过大或过小导致的梯度爆炸 / 消失问题\n",
    "        #   加速收敛：标准化后的数据能使梯度更新更均匀，减少训练时间\n",
    "        #   特征分布对齐：不同通道的特征可能具有不同的分布，标准化后可消除这种差异\n",
    "        # 这里为了简化,方便理解主流程,所以暂时忽略\n",
    "        # transforms.Normalize(mean=(train_mean,), std=(train_std,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 加载训练数据\n",
    "train_dataset = datasets.MNIST(root=\"../data/mnist/\", train=True, download=True, transform=transform)\n",
    "# 加载测试数据\n",
    "test_dataset = datasets.MNIST(root=\"../data/mnist/\", train=False, download=True, transform=transform)\n",
    "# 实例化训练数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,pin_memory=True,num_workers=4,persistent_workers=True)\n",
    "# 实例化测试数据加载器\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False,pin_memory=True,num_workers=4,persistent_workers=True)\n",
    "\n",
    "\n",
    "# 训练函数\n",
    "def train(model, device, train_loader, optimizer,scheduler, loss_history):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        # 将数据转移到指定计算资源设备上\n",
    "        # non_blocking=True 表示如果数据已经是 pinned memory（固定内存），\n",
    "        # 那么数据传输到 GPU 时可以异步进行，从而提高数据加载效率。\n",
    "        # pinned memory（锁页内存/固定内存）是指主机（CPU）内存中的一块特殊区域，\n",
    "        # 这块内存不会被操作系统换出到磁盘，因此可以被 GPU 直接高效地访问和拷贝。\n",
    "        # DataLoader 设置 pin_memory=True 时，会自动将加载的数据放到 pinned memory，\n",
    "        # 这样在调用 .to(device, non_blocking=True) 时，数据可以异步传输到 GPU，提高训练速度。\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()               # 清除梯度\n",
    "        outputs = model(inputs)             # 训练\n",
    "        loss = criterion(outputs, labels)   # 计算损失函数\n",
    "        loss.backward()                     # 反向传播\n",
    "        optimizer.step()                    # 更新参数\n",
    "        total_loss += loss.item()           # 记录训练集loss\n",
    "    # 记录训练集损失\n",
    "    loss_history.append(np.log10(total_loss))  # 将损失加入损失历史记录列表，由于数值有时较大，这里取对数\n",
    "    scheduler.step() # 更新学习率\n",
    "\n",
    "# 测试函数\n",
    "def test(model, device, test_loader, acc_history):\n",
    "    total_correct = 0\n",
    "    # 测试模型，不计算梯度\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # 将数据转移到指定计算资源设备上\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            # 预测\n",
    "            outputs = model(inputs)\n",
    "            # 记录测试集预测正确数\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    # 记录测试集准确率\n",
    "    acc_history.append(total_correct / len(test_dataset))  # 将准确率加入准确率历史记录列表\n",
    "\n",
    "\n",
    "# 设置epoch数并开始训练\n",
    "num_epochs = 10  # 设置epoch数\n",
    "loss_history = []  # 创建损失历史记录列表\n",
    "acc_history = []  # 创建准确率历史记录列表\n",
    "\n",
    "# tqdm用于显示进度条并评估任务时间开销\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train(model,device, train_loader, optimizer, scheduler, loss_history)\n",
    "    test(model,device, test_loader, acc_history)\n",
    "    # 打印 <8.4f : 左对齐，总宽度 8，保留 4 位小数。\n",
    "    tqdm.write(f\"Epoch: {epoch:<3} Loss: {loss_history[-1]:<8.4f} Accuracy: {acc_history[-1]:<8.4f}\")\n",
    "    \n",
    "\n",
    "\n",
    "# 使用Matplotlib绘制损失和准确率的曲线图\n",
    "plt.plot(loss_history, label=\"loss\")\n",
    "plt.plot(acc_history, label=\"accuracy\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 输出准确率\n",
    "print(\"Final Accuracy:\", acc_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf0385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"lenet5_mnist.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
