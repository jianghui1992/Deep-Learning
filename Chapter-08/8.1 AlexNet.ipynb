{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061374ac",
   "metadata": {},
   "source": [
    "### AlexNet代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4d62b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库，torchinfo用于查看模型结构\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eff219",
   "metadata": {},
   "source": [
    "### 结构定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "057ce823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义AlexNet的网络结构\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000, dropout=0.5):\n",
    "        super().__init__()\n",
    "        # 定义卷积层\n",
    "        self.features = nn.Sequential(\n",
    "            # 卷积+ReLU+最大池化\n",
    "            # 原始论文是在2个GPU上训练(每个48通道),后续都是单GPU/CPU训练,简化为64通道\n",
    "            # 这一调整既能保持模型的基本结构，又能减少约 30% 的参数量，提高训练效率\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            # inplace=False:默认值,经过Relu是生成一个新的变量,True:直接原地修改输入\n",
    "            # 可以节省内存占用,但是需要注意原始输入没有依赖才可以使用\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # 卷积+ReLU+最大池化\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # 卷积+ReLU\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 卷积+ReLU\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 卷积+ReLU\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 最大池化\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        # 自适应平均池化 : 它指定的是输出特征图的尺寸，而非池化窗口的大小或步长\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        # 定义全连接层\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Dropout+全连接层+ReLU\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Dropout+全连接层+ReLU\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 全连接层\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    # 定义前向传播函数\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)        # 提取特征\n",
    "        x = self.avgpool(x)         # 平均池化\n",
    "        x = torch.flatten(x, 1)     # 转换为1维张量\n",
    "        x = self.classifier(x)      # 使用全连接层训练\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496298fd",
   "metadata": {},
   "source": [
    "### 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ebca16f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "AlexNet                                  [1, 1000]                 --\n",
       "├─Sequential: 1-1                        [1, 256, 6, 6]            --\n",
       "│    └─Conv2d: 2-1                       [1, 64, 55, 55]           23,296\n",
       "│    └─ReLU: 2-2                         [1, 64, 55, 55]           --\n",
       "│    └─MaxPool2d: 2-3                    [1, 64, 27, 27]           --\n",
       "│    └─Conv2d: 2-4                       [1, 192, 27, 27]          307,392\n",
       "│    └─ReLU: 2-5                         [1, 192, 27, 27]          --\n",
       "│    └─MaxPool2d: 2-6                    [1, 192, 13, 13]          --\n",
       "│    └─Conv2d: 2-7                       [1, 384, 13, 13]          663,936\n",
       "│    └─ReLU: 2-8                         [1, 384, 13, 13]          --\n",
       "│    └─Conv2d: 2-9                       [1, 256, 13, 13]          884,992\n",
       "│    └─ReLU: 2-10                        [1, 256, 13, 13]          --\n",
       "│    └─Conv2d: 2-11                      [1, 256, 13, 13]          590,080\n",
       "│    └─ReLU: 2-12                        [1, 256, 13, 13]          --\n",
       "│    └─MaxPool2d: 2-13                   [1, 256, 6, 6]            --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [1, 256, 6, 6]            --\n",
       "├─Sequential: 1-3                        [1, 1000]                 --\n",
       "│    └─Dropout: 2-14                     [1, 9216]                 --\n",
       "│    └─Linear: 2-15                      [1, 4096]                 37,752,832\n",
       "│    └─ReLU: 2-16                        [1, 4096]                 --\n",
       "│    └─Dropout: 2-17                     [1, 4096]                 --\n",
       "│    └─Linear: 2-18                      [1, 4096]                 16,781,312\n",
       "│    └─ReLU: 2-19                        [1, 4096]                 --\n",
       "│    └─Linear: 2-20                      [1, 1000]                 4,097,000\n",
       "==========================================================================================\n",
       "Total params: 61,100,840\n",
       "Trainable params: 61,100,840\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 714.68\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 3.95\n",
       "Params size (MB): 244.40\n",
       "Estimated Total Size (MB): 248.96\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看模型结构及参数量，input_size表示示例输入数据的维度信息\n",
    "summary(AlexNet(), input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b837b9c",
   "metadata": {},
   "source": [
    "### torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66df0e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "AlexNet                                  [1, 1000]                 --\n",
       "├─Sequential: 1-1                        [1, 256, 6, 6]            --\n",
       "│    └─Conv2d: 2-1                       [1, 64, 55, 55]           23,296\n",
       "│    └─ReLU: 2-2                         [1, 64, 55, 55]           --\n",
       "│    └─MaxPool2d: 2-3                    [1, 64, 27, 27]           --\n",
       "│    └─Conv2d: 2-4                       [1, 192, 27, 27]          307,392\n",
       "│    └─ReLU: 2-5                         [1, 192, 27, 27]          --\n",
       "│    └─MaxPool2d: 2-6                    [1, 192, 13, 13]          --\n",
       "│    └─Conv2d: 2-7                       [1, 384, 13, 13]          663,936\n",
       "│    └─ReLU: 2-8                         [1, 384, 13, 13]          --\n",
       "│    └─Conv2d: 2-9                       [1, 256, 13, 13]          884,992\n",
       "│    └─ReLU: 2-10                        [1, 256, 13, 13]          --\n",
       "│    └─Conv2d: 2-11                      [1, 256, 13, 13]          590,080\n",
       "│    └─ReLU: 2-12                        [1, 256, 13, 13]          --\n",
       "│    └─MaxPool2d: 2-13                   [1, 256, 6, 6]            --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [1, 256, 6, 6]            --\n",
       "├─Sequential: 1-3                        [1, 1000]                 --\n",
       "│    └─Dropout: 2-14                     [1, 9216]                 --\n",
       "│    └─Linear: 2-15                      [1, 4096]                 37,752,832\n",
       "│    └─ReLU: 2-16                        [1, 4096]                 --\n",
       "│    └─Dropout: 2-17                     [1, 4096]                 --\n",
       "│    └─Linear: 2-18                      [1, 4096]                 16,781,312\n",
       "│    └─ReLU: 2-19                        [1, 4096]                 --\n",
       "│    └─Linear: 2-20                      [1, 1000]                 4,097,000\n",
       "==========================================================================================\n",
       "Total params: 61,100,840\n",
       "Trainable params: 61,100,840\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 714.68\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 3.95\n",
       "Params size (MB): 244.40\n",
       "Estimated Total Size (MB): 248.96\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看torchvision自带的模型结构及参数量\n",
    "from torchvision import models\n",
    "summary(models.alexnet(), input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b551b49",
   "metadata": {},
   "source": [
    "### mac GPU加速配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155dbc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "True\n",
      "True\n",
      "使用训练设备: mps\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 首先确认您的 PyTorch 版本是否支持 Metal 后端（Apple GPU 加速）\n",
    "print(torch.version.__version__)  # 应显示2.0.0或更高\n",
    "print(torch.backends.mps.is_available())  # 应显示True\n",
    "print(torch.backends.mps.is_built())     # 应显示True\n",
    "\n",
    "# 设备配置 - 启用AMD Radeon GPU加速\n",
    "# 设置设备，优先使用GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"使用训练设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09a91d",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ec145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型主设备: mps:0\n",
      "\n",
      "检查所有模型参数的设备:\n",
      "损失函数设备: N/A\n",
      "优化器参数设备: mps:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c9f2989d2147bbb1ccc474d3d1422e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9b4c20867c483283cbf0d45b53e0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 1/50:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb9ce945e8944f3894431c6c0894f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test  epoch 1/50:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1   Loss: 2.6569   Accuracy: 0.0225  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a7e8325d5e469e9c7ea4f42993058c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 2/50:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c004129bf7451a884d215de4a66fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test  epoch 2/50:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2   Loss: 5.0607   Accuracy: 0.0118  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccaa45bf3dc4b6cb1f0915b6a5de822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 3/50:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15145fad8af64e208c17e1bc598d5481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test  epoch 3/50:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3   Loss: 2.6673   Accuracy: 0.0137  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b7e476a34b43eb949faa6e8ee3b0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 4/50:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2c8b8cf416415080457caef72475c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test  epoch 4/50:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4   Loss: 2.6653   Accuracy: 0.0108  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5020cd5e877c4a0497affb52bc7a3574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 5/50:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b451559ec6244f48b03334ae26f45cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test  epoch 5/50:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5   Loss: 2.6676   Accuracy: 0.0127  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d863127e0814160aaa007bf9426a315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 6/50:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import sys,os\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(0)\n",
    "batch_size = 64\n",
    "num_workers = 8  # 8个工作线程\n",
    "\n",
    "# 设置训练集的数据变换，进行数据增强(会生成新的图像,来丰富数据)\n",
    "trainform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(30),              # 随机旋转 -30度到30度之间\n",
    "    \n",
    "    # 随机裁剪图像的一部分区域，然后将其调整为指定大小（224×224 像素）。\n",
    "    # 裁剪区域的大小和宽高比是随机的（默认范围：裁剪面积为原图的 0.08~1.0 倍，裁剪宽高比为 3/4~4/3）\n",
    "    # transforms.RandomResizedCrop((224, 224)),   # 随机比例裁剪并进行resize\n",
    "    \n",
    "    # 在原图中随机选择一个 224×224 的区域（不改变宽高比）。\n",
    "    transforms.RandomCrop(224),  # 比RandomResizedCrop计算量小\n",
    "\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),   # 随机水平翻转\n",
    "    transforms.RandomVerticalFlip(p = 0.5),     # 随机垂直翻转\n",
    "    transforms.ToTensor(),                      # 将数据转换为张量,并归一化到[0,1]区间\n",
    "    # 对三通道数据进行归一化(均值，标准差)，数值是从ImageNet数据集上的百万张图片中随机抽样计算得到\n",
    "    # 这些值被广泛用于预训练模型（如 ResNet、VGG、AlexNet 等）的输入预处理。\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 设置测试集的数据变换，不进行数据增强，仅使用resize和归一化\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 将图像的短边调整为指定长度（224 像素），长边按原始比例缩放\n",
    "    transforms.ToTensor(),  # 将数据转换为张量\n",
    "    # 对三通道数据进行归一化(均值，标准差)，数值是从ImageNet数据集上的百万张图片中随机抽样计算得到\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 加载训练数据，需要特别注意的是Flowers102数据集，test簇的数据量较多些，可以选择使用\"test\"作为训练集(本地太慢,还是用原始分类)\n",
    "# https://www.robots.ox.ac.uk/~vgg/data/flowers/102/categories.html\n",
    "train_dataset = datasets.Flowers102(root='../data/flowers102', split=\"test\", download=True, transform=trainform_train)\n",
    "# 加载测试数据，使用\"test\"作为测试集\n",
    "test_dataset = datasets.Flowers102(root='../data/flowers102', split=\"train\", download=True, transform=transform_test)\n",
    "\n",
    "# 实例化训练数据加载器\n",
    "# num_workers参数指定了用于数据加载的子进程数量来加速数据加载\n",
    "# GPU模式启用pin_memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=num_workers,pin_memory=True,persistent_workers=True)\n",
    "# 实例化测试数据加载器\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers,pin_memory=True,persistent_workers=True)\n",
    "\n",
    "# 定义模型、优化器、损失函数\n",
    "# 使用预训练模型 - 简化架构适合CPU\n",
    "from torchvision.models import AlexNet_Weights\n",
    "# weights=AlexNet_Weights.IMAGENET1K_V1 等同于旧版的 pretrained=True，使用在 ImageNet 上预训练的权重\n",
    "# 如果你想要使用最新的预训练权重，可以用 weights=AlexNet_Weights.DEFAULT\n",
    "# model = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "# 冻结大部分预训练层，只训练最后几层\n",
    "# for param in list(model.parameters())[:-4]:\n",
    "#     param.requires_grad = False\n",
    "# 修改分类器适应Flower102\n",
    "# 简化分类器结构\n",
    "# num_ftrs = model.classifier[6].in_features\n",
    "# model.classifier[6] = nn.Linear(num_ftrs, 102)\n",
    "model = AlexNet(num_classes=102).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# 优化器 - 使用针对GPU优化的AdamW\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.001,  # AdamW通常使用较低的学习率\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# 设置epoch数并开始训练\n",
    "num_epochs = 50  # 设置epoch数\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "loss_history = []  # 创建损失历史记录列表\n",
    "acc_history = []   # 创建准确率历史记录列表\n",
    "\n",
    "\n",
    "# 检查模型设备\n",
    "print(f\"模型主设备: {next(model.parameters()).device}\")\n",
    "# 递归检查所有参数\n",
    "print(\"\\n检查所有模型参数的设备:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.device.type != 'mps':\n",
    "        print(f\"警告: 参数 {name} 在 {param.device} 而非 MPS 设备上!\")\n",
    "# 检查损失函数设备\n",
    "print(f\"损失函数设备: {criterion.device if hasattr(criterion, 'device') else 'N/A'}\")\n",
    "# 检查优化器\n",
    "print(f\"优化器参数设备: {optimizer.param_groups[0]['params'][0].device}\")\n",
    "\n",
    "\n",
    "# 检查数据加载器\n",
    "# print(\"\\n检查数据加载器输出的设备:\")\n",
    "# inputs, labels = next(iter(dataloaders['train']))\n",
    "# print(f\"输入数据设备: {inputs.device}\")\n",
    "# print(f\"标签设备: {labels.device}\")\n",
    "\n",
    "\n",
    "# tqdm用于显示进度条并评估任务时间开销\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # 记录损失和预测正确数\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    # 批量训练\n",
    "    model.train()\n",
    "    progress_bar = tqdm(train_loader, total=len(train_loader), desc=f'train epoch {epoch+1}/{num_epochs}')\n",
    "    for inputs, labels in progress_bar:\n",
    "        # 将数据转移到指定计算资源设备上\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        # 预测、损失函数、反向传播\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # 记录训练集loss\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{np.log10(loss.item()):.4f}','lr':f'{optimizer.param_groups[0]['lr']:.4f}'})\n",
    "        \n",
    "    \n",
    "    # 测试模型，不计算梯度\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # progress_bar = tqdm(enumerate(test_loader), total=len(test_loader), desc=f'test epoch {epoch+1}/{num_epochs}')\n",
    "        progress_bar = tqdm(test_loader, total=len(test_loader), desc=f'test  epoch {epoch+1}/{num_epochs}')\n",
    "        for inputs, labels in progress_bar:\n",
    "            # 将数据转移到指定计算资源设备上\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 预测\n",
    "            outputs = model(inputs)\n",
    "            # 记录测试集预测正确数\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            # progress_bar.set_postfix({'acc': f'{100 * correct / total:.2f}%'})\n",
    "\n",
    "        \n",
    "    # 记录训练集损失和测试集准确率\n",
    "    loss_history.append(np.log10(total_loss))  # 将损失加入损失历史记录列表，由于数值有时较大，这里取对数\n",
    "    acc_history.append(total_correct / len(test_dataset))# 将准确率加入准确率历史记录列表\n",
    "    \n",
    "    # 打印中间值\n",
    "    tqdm.write(f\"Epoch: {epoch+1:<3} Loss: {loss_history[-1]:<8.4f} Accuracy: {acc_history[-1]:<8.4f}\")\n",
    "\n",
    "# 使用Matplotlib绘制损失和准确率的曲线图\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history, label='loss')\n",
    "plt.plot(acc_history, label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 输出准确率\n",
    "print(\"Final Accuracy:\", acc_history[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
